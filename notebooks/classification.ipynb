{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification\n",
        "## MI201\n",
        "\n",
        "##**Group 4** :\n",
        "- Diego FLEURY CORRÊA DE MORAES\n",
        "- Hazael SOLEDADE DE ARAUJO JUMONJI\n",
        "- Lucas DE OLIVEIRA MARTIM\n",
        "\n",
        "### Project 3 : **Sentiment Analysis Using LLMs**"
      ],
      "metadata": {
        "id": "HT5-j4wF4BET"
      },
      "id": "HT5-j4wF4BET"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import unicodedata\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "metadata": {
        "id": "njRjm1wQBwhN"
      },
      "id": "njRjm1wQBwhN",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Data"
      ],
      "metadata": {
        "id": "BLhb6oA8BE8m"
      },
      "id": "BLhb6oA8BE8m"
    },
    {
      "cell_type": "code",
      "source": [
        "train_full = pd.read_csv('processed_train.csv')\n",
        "test_full = pd.read_csv('processed_test.csv')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_full['Text'], train_full['Sentiment'], test_size=0.2, random_state=42)\n",
        "X_test, y_test = test_full['Text'], test_full['Sentiment']"
      ],
      "metadata": {
        "id": "wOYLIiRHBprl"
      },
      "id": "wOYLIiRHBprl",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.reset_index(drop=True, inplace=True)\n",
        "X_val.reset_index(drop=True, inplace=True)\n",
        "X_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "y_train.reset_index(drop=True, inplace=True)\n",
        "y_val.reset_index(drop=True, inplace=True)\n",
        "y_test.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "g6nk99U2NChx"
      },
      "id": "g6nk99U2NChx",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Text preprocessing, removing accents, links, HTML, extra spaces and user names.\n",
        "\n",
        "    - Converts to lowercase.\n",
        "    - Removes accents.\n",
        "    - Removes HTML tags.\n",
        "    - Remove links (http, https, www).\n",
        "    - Removes extra spaces.\n",
        "    - Removes user names.\n",
        "    \"\"\"\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Strip all accents\n",
        "    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "    # Removes links (http, https, www)\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "\n",
        "    # Removes HTML tags\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)\n",
        "\n",
        "    # Removes usernames\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)\n",
        "\n",
        "    # Removes line breaks and excessive whitespaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "jvX1qnqhCnNE"
      },
      "id": "jvX1qnqhCnNE",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.apply(preprocess_text)\n",
        "X_val = X_val.apply(preprocess_text)\n",
        "X_test = X_test.apply(preprocess_text)"
      ],
      "metadata": {
        "id": "DM62ZEeaG_Tj"
      },
      "execution_count": 25,
      "outputs": [],
      "id": "DM62ZEeaG_Tj"
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_mapping = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
        "y_train = y_train.map(sentiment_mapping)\n",
        "y_val = y_val.map(sentiment_mapping)\n",
        "y_test = y_test.map(sentiment_mapping)"
      ],
      "metadata": {
        "id": "ZNwV2g7bHY2C"
      },
      "id": "ZNwV2g7bHY2C",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "BxLPclbdLmNj",
        "outputId": "60daef7a-6e11-4f92-ff6c-b3de1f0b894c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "id": "BxLPclbdLmNj",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        oh, he`s hilarious. i`m just commenting on the...\n",
              "1        thanks for trying i was hoping bud trillin, bu...\n",
              "2        after show at our house rocked! saying goodbye...\n",
              "3        up at 4:30am west coast time..gettin ready to ...\n",
              "4        my computer is so slooowww this morning. i thi...\n",
              "                               ...                        \n",
              "21979                               feels like warm things\n",
              "21980                my best friend is in vegas without me\n",
              "21981                   - fire and urban at rock challenge\n",
              "21982                                 a+ for effort though\n",
              "21983    claire love the show, got into the office @ 5a...\n",
              "Name: Text, Length: 21984, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>oh, he`s hilarious. i`m just commenting on the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thanks for trying i was hoping bud trillin, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>after show at our house rocked! saying goodbye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>up at 4:30am west coast time..gettin ready to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>my computer is so slooowww this morning. i thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21979</th>\n",
              "      <td>feels like warm things</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21980</th>\n",
              "      <td>my best friend is in vegas without me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21981</th>\n",
              "      <td>- fire and urban at rock challenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21982</th>\n",
              "      <td>a+ for effort though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21983</th>\n",
              "      <td>claire love the show, got into the office @ 5a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21984 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "z0Gprp13KlT2",
        "outputId": "8bd598e3-c555-41e2-ce95-34eff2b5c467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "id": "z0Gprp13KlT2",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1\n",
              "1        1\n",
              "2        0\n",
              "3        1\n",
              "4        0\n",
              "        ..\n",
              "21979    0\n",
              "21980    0\n",
              "21981    0\n",
              "21982    1\n",
              "21983    1\n",
              "Name: Sentiment, Length: 21984, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21979</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21980</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21981</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21982</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21983</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21984 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Extract embeddings for all data\n",
        "def extract_embeddings(model, dataloader, device):\n",
        "    \"\"\"\n",
        "    Extracts embeddings for all data using a pre-trained BERT model.\n",
        "\n",
        "    Args:\n",
        "        model (transformers.BertModel): Pre-trained BERT model.\n",
        "        dataloader (DataLoader): DataLoader for the dataset.\n",
        "        device (torch.device): Device to run the model on (CPU or GPU).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A matrix of size (number_of_samples, embedding_size).\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    embeddings = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "\n",
        "            # Forward pass through BERT\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            pooled_output = outputs.pooler_output  # CLS token representation\n",
        "\n",
        "            # Append embeddings to the list\n",
        "            embeddings.append(pooled_output.cpu())\n",
        "\n",
        "    # Combine all embeddings into a single matrix\n",
        "    return torch.cat(embeddings, dim=0)\n",
        "\n",
        "# Custom Dataset\n",
        "class EmbeddingDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            texts (list): List of text samples.\n",
        "            labels (list): List of sentiment labels (e.g., 0, 1).\n",
        "            tokenizer (transformers.BertTokenizer): Tokenizer for BERT.\n",
        "            max_length (int): Maximum length for tokenized sequences.\n",
        "        \"\"\"\n",
        "        self.embeddings = embeddings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Tokenize and encode the text\n",
        "        embeddings = self.embeddings[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": embeddings.squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "meidY0NVsChh"
      },
      "execution_count": 29,
      "outputs": [],
      "id": "meidY0NVsChh"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "PRETRAINED_MODEL = \"bert-base-uncased\"\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASSES = 3\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n",
        "\n",
        "# Initialize the datasets\n",
        "train_dataset = TextDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
        "val_dataset = TextDataset(X_val, y_val, tokenizer, MAX_LENGTH)\n",
        "\n",
        "# Initialize the dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Get the bert model\n",
        "bert = BertModel.from_pretrained(PRETRAINED_MODEL).to(device)\n",
        "\n",
        "# Extract embeddings (train)\n",
        "train_embeddings = extract_embeddings(bert, train_loader, device)\n",
        "train_embeddings =train_embeddings.cpu()\n",
        "\n",
        "# Extract embeddings (val)\n",
        "val_embeddings = extract_embeddings(bert, val_loader, device)\n",
        "val_embeddings =val_embeddings.cpu()\n"
      ],
      "metadata": {
        "id": "oHDGdX5EIbsR"
      },
      "id": "oHDGdX5EIbsR",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings.size(), val_embeddings.size()"
      ],
      "metadata": {
        "id": "XAWR5yu1OQmG",
        "outputId": "5495da8f-1f3e-49f8-c3b2-5e223b433603",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XAWR5yu1OQmG",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([21984, 768]), torch.Size([5496, 768]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding datasets\n",
        "embedding_train_dataset = EmbeddingDataset(train_embeddings, y_train)\n",
        "embedding_val_dataset = EmbeddingDataset(val_embeddings, y_val)\n",
        "\n",
        "# Initialize the embedding dataloaders\n",
        "embedding_train_loader = DataLoader(embedding_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "embedding_val_loader = DataLoader(embedding_val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "W0X6VeclzYro"
      },
      "execution_count": 33,
      "outputs": [],
      "id": "W0X6VeclzYro"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classical ML (SVM, Random Forest, XGBoost)"
      ],
      "metadata": {
        "id": "5amz4R5z4vCZ"
      },
      "id": "5amz4R5z4vCZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "Syg-B3uq5TwI"
      },
      "id": "Syg-B3uq5TwI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "cWvzXwDG5VLR"
      },
      "id": "cWvzXwDG5VLR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "-O-Ff9T55W1g"
      },
      "id": "-O-Ff9T55W1g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "4ZL42k8R45tJ"
      },
      "id": "4ZL42k8R45tJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM"
      ],
      "metadata": {
        "id": "rHPnW0Mo5FWZ"
      },
      "id": "rHPnW0Mo5FWZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning with LoRA"
      ],
      "metadata": {
        "id": "Omt_e4jq5KAB"
      },
      "id": "Omt_e4jq5KAB"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uez-YDsz4msn"
      },
      "id": "Uez-YDsz4msn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "",
      "name": ""
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}